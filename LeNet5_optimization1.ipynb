{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c24712e-36d2-43d1-9a34-9d1cf7e90dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 optimization try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d343d1e0-c885-4a7f-8388-bb1d29153c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# install torch\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058280de-56e7-4578-9bb0-afcd3394ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b68b1fe6-5004-4307-a7d3-1f160d951396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # For activation functions and pooling\n",
    "import torch.optim as optim  # # For optimizers (SGD, Adam, etc.)\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e969af2d-3cca-410b-8d84-384f131cd434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, else fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd7f76e-b4d2-44ad-b9dd-dbb9aa81a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# data is in this folder\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aa1f521-8c82-4b9a-a2c0-9ef98b2bbea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lilywenger/MLM25/GitProjects/DigitRecognizer_Inkvestigators_mlm25/digit-recognizer'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d508f2-c536-4743-9d2a-fb375e0514c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9cf9461-3884-4566-89d1-aabafc642a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating out the labels from the pixel data features\n",
    "X_train = train_df.drop('label', axis=1).values   # shape: (42000, 784)\n",
    "y_train = train_df['label'].values                # shape: (42000,)\n",
    "X_test = test_df.values                           # shape: (28000, 784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a2a4596-5159-443c-abd3-17dd52e7ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert to PyTorch tensors and reshape\n",
    "# converts to float32 and normalizes to [0,1]\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor  = torch.tensor(X_test, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "434ab2f1-3b31-4ff3-8f12-2aa7186ac18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data mean: 0.1310, std: 0.3085\n"
     ]
    }
   ],
   "source": [
    "# check the mean and standard deviation from the normalization\n",
    "# should be mean 0 and std of 1\n",
    "mean = X_train_tensor.mean().item()\n",
    "std = X_train_tensor.std().item()\n",
    "print(f\"Training data mean: {mean:.4f}, std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01a07933-7300-4802-ac4b-0024e8462581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into 80 train and 20 validate from train\n",
    "train_size = int(0.8*len(X_train_tensor))\n",
    "val_size = len(X_train_tensor)-train_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor),\n",
    "    [train_size, val_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4241423b-dca2-4977-aeae-d6613e0823f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing up the data loaders \n",
    "# allows for batches of specified size to make training more efficient\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader  = DataLoader(X_test_tensor, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2854377c-0200-46f8-af7b-d54379bebe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimized LeNet model\n",
    "# differences from the baseline model include using: \n",
    "# ReLU instead of tanh, MaxPool instead of AvgPool, BatchNorm for stability, and Dropout for normalization\n",
    "class LeNet5_Optimized(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5_Optimized, self).__init__()\n",
    "        # Convolutional layer 1: 1 input channel, 6 output feature maps\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.bn1   = nn.BatchNorm2d(6)            # BatchNorm stabilizes learning\n",
    "        \n",
    "        # Convolutional layer 2: 6 input, 16 output channels\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)     # Flattened conv output → 120\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)              # 10 digits → 10 output logits\n",
    "        \n",
    "        # Dropout regularization (prevents overfitting)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---- Conv Block 1 ----\n",
    "        # Conv → BatchNorm → ReLU → MaxPool\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # ---- Conv Block 2 ----\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # ---- Flatten ----\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # ---- Fully Connected Layers ----\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)             # Drop neurons to avoid overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)                 # Output raw logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51350d87-7eb6-492a-8727-bd520a111e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training set up\n",
    "model = LeNet5_Optimized().to(device)\n",
    "\n",
    "# CrossEntropyLoss combines softmax + negative log likelihood.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam optimizer adapts learning rates for each parameter.\n",
    "# weight_decay adds L2 regularization for further generalization.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler gradually decreases the LR every 5 epochs by 20%.\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "246cba1a-9357-4532-85fc-f50b69d1700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Train Loss: 0.0418 | Val Loss: 0.0497 | Val Acc: 98.81%\n",
      "Epoch [2/50] | Train Loss: 0.0355 | Val Loss: 0.0524 | Val Acc: 98.76%\n",
      "Epoch [3/50] | Train Loss: 0.0331 | Val Loss: 0.0529 | Val Acc: 98.76%\n",
      "Epoch [4/50] | Train Loss: 0.0302 | Val Loss: 0.0492 | Val Acc: 98.89%\n",
      "Epoch [5/50] | Train Loss: 0.0296 | Val Loss: 0.0513 | Val Acc: 98.81%\n",
      "Epoch [6/50] | Train Loss: 0.0262 | Val Loss: 0.0547 | Val Acc: 98.73%\n",
      "Epoch [7/50] | Train Loss: 0.0242 | Val Loss: 0.0582 | Val Acc: 98.71%\n",
      "Epoch [8/50] | Train Loss: 0.0230 | Val Loss: 0.0549 | Val Acc: 98.90%\n",
      "Epoch [9/50] | Train Loss: 0.0213 | Val Loss: 0.0575 | Val Acc: 98.87%\n",
      "Epoch [10/50] | Train Loss: 0.0200 | Val Loss: 0.0532 | Val Acc: 98.87%\n",
      "Epoch [11/50] | Train Loss: 0.0226 | Val Loss: 0.0546 | Val Acc: 98.80%\n",
      "Epoch [12/50] | Train Loss: 0.0161 | Val Loss: 0.0584 | Val Acc: 98.83%\n",
      "Epoch [13/50] | Train Loss: 0.0169 | Val Loss: 0.0602 | Val Acc: 98.85%\n",
      "Early stopping triggered at epoch 13\n",
      "Training completed. Best validation accuracy: 98.90%\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "epochs=50\n",
    "patience=5\n",
    "best_val_acc=0.0\n",
    "epochs_no_improve=0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()                        # Enable dropout + batchnorm updates\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # ---- Training phase ----\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()            # Reset gradient buffers\n",
    "        output = model(data)             # Forward pass\n",
    "        loss = criterion(output, target) # Compute cross-entropy loss\n",
    "        loss.backward()                  # Backpropagate gradients\n",
    "        optimizer.step()                 # Update weights\n",
    "        \n",
    "        running_loss += loss.item()      # Accumulate batch loss\n",
    "    \n",
    "    scheduler.step()                     # Adjust learning rate schedule if using scheduler\n",
    "    \n",
    "    # ---- Validation phase ----\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # ---- Early Stopping Logic ----\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model weights\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    # Stop if validation accuracy hasn't improved for 'patience' epochs\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Load the best model weights before generating predictions\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f13d168-c9c9-4c52-a7c9-5ee0fbae8a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'LeNet5_Optimized_submission_LW.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate csv for submission\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)  # Convert logits → predicted labels\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Create submission DataFrame (format required by Kaggle)\n",
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": np.arange(1, len(predictions) + 1),\n",
    "    \"Label\": predictions\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "submission.to_csv(\"LeNet5_Optimized_submission_LW.csv\", index=False)\n",
    "print(\"Submission file 'LeNet5_Optimized_submission_LW.csv' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308204b9-8c8d-4328-8767-a10c754e4044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook LeNet5_optimization1.ipynb to script\n",
      "[NbConvertApp] Writing 7717 bytes to LeNet5_optimization1.py\n"
     ]
    }
   ],
   "source": [
    "# convert to .py file\n",
    "!jupyter nbconvert --to script LeNet5_optimization1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c434a8c0-1360-486e-9bc0-b06ce70b70f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get misclassified indices\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m misclassified_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m!=\u001b[39m y_pred)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Show a few\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Get misclassified indices\n",
    "misclassified_idx = np.where(y_val != y_pred)[0]\n",
    "\n",
    "# Show a few\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, idx in enumerate(misclassified_idx[:9]):\n",
    "    image = np.array(X_val.iloc[idx]).reshape(28, 28)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"True: {y_val.iloc[idx]}, Pred: {y_pred[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a642e1-553a-446b-a805-0b7bd5891044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
